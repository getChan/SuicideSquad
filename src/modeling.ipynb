{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import preprocessing as pre\n",
    "import tensorflow.contrib.layers as layers\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label = pre.getDataFrame('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_label = pre.getDataFrame('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 30, 112, 112, 3), (4, 5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 30, 112, 112, 3), (4, 5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19b92257a20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[1][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self,\n",
    "            num_class = 5,\n",
    "            keep_prob = 0.6,\n",
    "            batch_size = 5,\n",
    "            epoch=1,\n",
    "            lr = 1e-4):\n",
    "        self.IMG_WIDTH = 112\n",
    "        self.IMG_HEIGHT = 112\n",
    "        \n",
    "        self.graph = tf.Graph()\n",
    "        self.num_class = num_class\n",
    "        self.epoch = epoch\n",
    "        self.CLIP_LENGTH = 30\n",
    "        self.keep_prob = keep_prob\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.n_step_epoch=int(30/batch_size)\n",
    "        with self.graph.as_default():\n",
    "            # [batch, in_depth, in_height, in_width, in_channels]\n",
    "            self.inputs = tf.placeholder(tf.float32, [None, self.CLIP_LENGTH, self.IMG_HEIGHT, self.IMG_WIDTH, 3])\n",
    "            self.labels = tf.placeholder(tf.int64, [None, self.num_class])\n",
    "\n",
    "            self.initializer = layers.xavier_initializer()\n",
    "            self.global_step = tf.Variable(0, trainable = False, name = \"global_step\")\n",
    "            self.lr = lr\n",
    "            tf.add_to_collection(tf.GraphKeys.GLOBAL_STEP, self.global_step)\n",
    "         \n",
    "    def conv3d(self, inputs, shape, name, w_name, b_name):\n",
    "        with self.graph.as_default():\n",
    "            with tf.variable_scope('var_name') as var_scope:\n",
    "                W = tf.get_variable(name = w_name, shape = shape, initializer = self.initializer, dtype = tf.float32)\n",
    "                b = tf.get_variable(name = b_name, shape = shape[-1], initializer = tf.zeros_initializer(), dtype = tf.float32)\n",
    "                tf.add_to_collection(tf.GraphKeys.WEIGHTS, W)\n",
    "                tf.add_to_collection(tf.GraphKeys.BIASES, b)\n",
    "            return tf.nn.relu(tf.nn.bias_add(tf.nn.conv3d(inputs, W, strides = [1, 1, 1, 1, 1], padding = \"SAME\"), b))\n",
    "        \n",
    "    def fc(self, inputs, shape, name,w_name,b_name,activation = True):\n",
    "        with self.graph.as_default():\n",
    "            with tf.variable_scope('var_name') as var_scope:\n",
    "                W = tf.get_variable(name = w_name, shape = shape, initializer = self.initializer, dtype = tf.float32)\n",
    "                b = tf.get_variable(name = b_name, shape = shape[-1], initializer = tf.zeros_initializer(), dtype = tf.float32)\n",
    "                tf.add_to_collection(tf.GraphKeys.WEIGHTS, W)\n",
    "                tf.add_to_collection(tf.GraphKeys.BIASES, b)\n",
    "\n",
    "            if activation:\n",
    "                return tf.nn.relu(tf.nn.bias_add(tf.matmul(inputs, W), b))\n",
    "            else:\n",
    "                return tf.nn.bias_add(tf.matmul(inputs, W), b)\n",
    "            \n",
    "    def parseNet(self, net, netstruct, istraining = True):\n",
    "        for key in netstruct:\n",
    "            if key[0] == \"conv\":\n",
    "                net = self.conv3d(net, key[2], key[1],key[3], key[4])\n",
    "            elif key[0] == \"fc\":\n",
    "                net = self.fc(net, key[2], key[1], key[3], key[4],activation = key[-1])\n",
    "            elif key[0] == \"maxpool\":\n",
    "                net = tf.nn.max_pool3d(net, ksize = key[2], strides = key[2], padding = \"SAME\", name = key[1])\n",
    "            elif key[0] == \"dropout\" and istraining:\n",
    "                net = tf.nn.dropout(net, key[2], name = key[1])\n",
    "            elif key[0] == \"reshape\":\n",
    "                net = tf.reshape(net, key[-1])\n",
    "            elif key[0] == \"softmax\":\n",
    "                net = tf.nn.softmax(net)\n",
    "            elif key[0] == \"transpose\":\n",
    "                net = tf.transpose(net, perm=key[-1])\n",
    "        return net\n",
    "\n",
    "    def train(self, data, label):\n",
    "        with self.graph.as_default():\n",
    "            \n",
    "#             [filter_depth, filter_height, filter_width, in_channels, out_channels]\n",
    "            c3d_net = [\n",
    "                [\"conv\", \"conv1\", [3, 3, 3, 3, 64], 'wc1', 'bc1'],\n",
    "                [\"maxpool\", \"pool1\", [1, 1, 2, 2, 1]],\n",
    "                [\"conv\", \"conv2\", [3, 3, 3, 64, 128], 'wc2', 'bc2'],\n",
    "                [\"maxpool\", \"pool2\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv3a\", [3, 3, 3, 128, 256], 'wc3a', 'bc3a'],\n",
    "                [\"conv\", \"conv3b\", [3, 3, 3, 256, 256], 'wc3b', 'bc3b'],\n",
    "                [\"maxpool\", \"pool3\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv4a\", [3, 3, 3, 256, 512], 'wc4a', 'bc4a'],\n",
    "                [\"conv\", \"conv4b\", [3, 3, 3, 512, 512], 'wc4b', 'bc4b'],\n",
    "                [\"maxpool\", \"pool4\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv5a\", [3, 3, 3, 512, 512], 'wc5a', 'bc5a'],\n",
    "                [\"conv\", \"conv5b\", [3, 3, 3, 512, 256], 'wc5b', 'bc5b'],\n",
    "                [\"maxpool\", \"pool5\", [1, 2, 2, 2, 1]],\n",
    "                [\"transpose\", [0, 1, 4, 2, 3]],  #only use it if you restore the sports1m_finetuning_ucf101.model, otherwise uncomment it,(e.g use conv3d_deepnetA_sport1m_iter_1900000_TF.model)\n",
    "                [\"reshape\", [-1, 8192]],\n",
    "                [\"fc\", \"fc1\", [8192, 4096], 'wd1', 'bd1', True],\n",
    "                [\"dropout\", \"dropout1\", self.keep_prob],\n",
    "                [\"fc\", \"fc2\", [4096, 4096],'wd2','bd2', True],\n",
    "                [\"dropout\", \"dropout2\", self.keep_prob],\n",
    "                [\"fc\", \"fc3\", [4096, self.num_class],'wout','bout',False],\n",
    "            ]\n",
    "\n",
    "            # print(tf.trainable_variables())\n",
    "            # print(var_list)\n",
    "            # print(tf.get_collection(tf.GraphKeys.WEIGHTS))\n",
    "\n",
    "            # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.5)\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                logits = self.parseNet(self.inputs, c3d_net)\n",
    "                softmax_logits = tf.nn.softmax(logits)\n",
    "                # int_label = tf.one_hot(self.labels, self.num_class)\n",
    "                int_label = self.labels  # [bs,101]-->[bs*4 or 8 or 16,101]\n",
    "                # int_label=tf.concat(\n",
    "                #     [int_label,int_label,int_label,int_label,],axis=0)\n",
    "\n",
    "                int_label=tf.cast(int_label,dtype=tf.int64)\n",
    "#                 task_loss = tf.reduce_sum(\n",
    "#                     tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=int_label))\n",
    "                task_loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = int_label))\n",
    "                # task_loss = -tf.reduce_sum(int_label*tf.log(logits))\n",
    "#                 acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(softmax_logits, axis=1), int_label), tf.float32))\n",
    "#                 right_count = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(softmax_logits, axis=1), int_label), tf.int32))\n",
    "    \n",
    "                reg_loss = layers.apply_regularization(layers.l2_regularizer(5e-4),\n",
    "                                                       tf.get_collection(tf.GraphKeys.WEIGHTS))\n",
    "                total_loss = task_loss + reg_loss\n",
    "                train_var_list = [v for v in tf.trainable_variables() if v.name.find(\"conv\") == -1]\n",
    "                train_op = tf.train.GradientDescentOptimizer(self.lr).minimize(\n",
    "                    total_loss, global_step=self.global_step)\n",
    "#                 train_op = tf.train.MomentumOptimizer(self.lr,0.9).minimize(\n",
    "#                     total_loss, global_step = self.global_step,var_list=train_var_list)\n",
    "#                 train_op = tf.train.AdamOptimizer(self.lr).minimize(total_loss)\n",
    "    \n",
    "    \n",
    "                total_para = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])\n",
    "                print('total_para:', total_para)\n",
    "\n",
    "                init = tf.global_variables_initializer()\n",
    "                # var_list = [v for v in tf.trainable_variables() if v.name.find(\"conv\") != -1]\n",
    "                # print(var_list)\n",
    "                # saver = tf.train.Saver(tf.global_variables())\n",
    "                sess.run(init)\n",
    "                saver = tf.train.Saver(tf.trainable_variables())\n",
    "                ############################################################\n",
    "                saver.restore(sess, tf.train.latest_checkpoint('../model/'))\n",
    "                ############################################################\n",
    "\n",
    "                # print(\"Model Loading Done!\")\n",
    "                step = 0\n",
    "                total_batch = int(len(data) / self.batch_size)\n",
    "                for epoch in range(self.epoch):\n",
    "                    next_start_pos = 0\n",
    "                    total_cost = 0\n",
    "                    for i in tqdm(range(total_batch)):\n",
    "                        train_batch = data[next_start_pos:next_start_pos+self.batch_size] \n",
    "                        label_batch = label[next_start_pos:next_start_pos+self.batch_size] \n",
    "                        next_start_pos += self.batch_size \n",
    "                        assert len(train_batch)==self.batch_size\n",
    "                        val_feed = {self.inputs: train_batch, self.labels: label_batch}\n",
    "#                         print(sess.run(tf.size(logits), val_feed))\n",
    "                        _, cost = sess.run([train_op, task_loss], val_feed)\n",
    "                        total_cost += cost\n",
    "                    print('Avg. cost:', total_cost / total_batch)\n",
    "                saver.save(sess, '../model/c3d.ckpt')\n",
    "                \n",
    "    def test(self, data, label):\n",
    "        with self.graph.as_default():\n",
    "            \n",
    "#             [filter_depth, filter_height, filter_width, in_channels, out_channels]\n",
    "            c3d_net = [\n",
    "                [\"conv\", \"conv1\", [3, 3, 3, 3, 64], 'wc1', 'bc1'],\n",
    "                [\"maxpool\", \"pool1\", [1, 1, 2, 2, 1]],\n",
    "                [\"conv\", \"conv2\", [3, 3, 3, 64, 128], 'wc2', 'bc2'],\n",
    "                [\"maxpool\", \"pool2\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv3a\", [3, 3, 3, 128, 256], 'wc3a', 'bc3a'],\n",
    "                [\"conv\", \"conv3b\", [3, 3, 3, 256, 256], 'wc3b', 'bc3b'],\n",
    "                [\"maxpool\", \"pool3\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv4a\", [3, 3, 3, 256, 512], 'wc4a', 'bc4a'],\n",
    "                [\"conv\", \"conv4b\", [3, 3, 3, 512, 512], 'wc4b', 'bc4b'],\n",
    "                [\"maxpool\", \"pool4\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv5a\", [3, 3, 3, 512, 512], 'wc5a', 'bc5a'],\n",
    "                [\"conv\", \"conv5b\", [3, 3, 3, 512, 256], 'wc5b', 'bc5b'],\n",
    "                [\"maxpool\", \"pool5\", [1, 2, 2, 2, 1]],\n",
    "                [\"transpose\", [0, 1, 4, 2, 3]],  #only use it if you restore the sports1m_finetuning_ucf101.model, otherwise uncomment it,(e.g use conv3d_deepnetA_sport1m_iter_1900000_TF.model)\n",
    "                [\"reshape\", [-1, 8192]],\n",
    "                [\"fc\", \"fc1\", [8192, 4096], 'wd1', 'bd1', True],\n",
    "                [\"dropout\", \"dropout1\", self.keep_prob],\n",
    "                [\"fc\", \"fc2\", [4096, 4096],'wd2','bd2', True],\n",
    "                [\"dropout\", \"dropout2\", self.keep_prob],\n",
    "                [\"fc\", \"fc3\", [4096, self.num_class],'wout','bout',False],\n",
    "            ]\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                logits = self.parseNet(self.inputs, c3d_net)\n",
    "                softmax_logits = tf.nn.softmax(logits)\n",
    "\n",
    "                int_label = self.labels\n",
    "\n",
    "                int_label=tf.cast(int_label,dtype=tf.int64)\n",
    "\n",
    "#                 right_count = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(softmax_logits, axis=1), int_label), tf.int32))    \n",
    "                acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, axis=1), tf.argmax(int_label, axis=1)), tf.float32))\n",
    "                total_para = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])\n",
    "                print('total_para:', total_para)\n",
    "\n",
    "                init = tf.global_variables_initializer()\n",
    "                \n",
    "                sess.run(init)\n",
    "                saver = tf.train.Saver(tf.trainable_variables())\n",
    "                saver.restore(sess, tf.train.latest_checkpoint('../model/'))\n",
    "                print(\"Model Loading Done!\")\n",
    "                \n",
    "#                 total_batch = int(len(data) / self.batch_size)\n",
    "                \n",
    "#                 next_start_pos = 0\n",
    "#                 cnt = 0\n",
    "                \n",
    "#                 for i in tqdm(range(total_batch)):\n",
    "#                     test_batch = data[next_start_pos:next_start_pos+self.batch_size] \n",
    "#                     label_batch = label[next_start_pos:next_start_pos+self.batch_size] \n",
    "#                     next_start_pos += self.batch_size \n",
    "#                     assert len(test_batch)==self.batch_size\n",
    "#                     val_feed = {self.inputs: test_batch, self.labels: label_batch}\n",
    "# #                         print(sess.run(tf.size(logits), val_feed))\n",
    "#                     cnt += sess.run(right_count, val_feed)\n",
    "                test_data = data\n",
    "                test_label = label\n",
    "            \n",
    "                val_feed = {self.inputs: test_data, self.labels:test_label}\n",
    "                \n",
    "                    \n",
    "                print('Accuracy:', sess.run(acc, val_feed))\n",
    "                \n",
    "    def run(self, data, label):\n",
    "        with self.graph.as_default():\n",
    "            c3d_net = [\n",
    "                [\"conv\", \"conv1\", [3, 3, 3, 3, 64], 'wc1', 'bc1'],\n",
    "                [\"maxpool\", \"pool1\", [1, 1, 2, 2, 1]],\n",
    "                [\"conv\", \"conv2\", [3, 3, 3, 64, 128], 'wc2', 'bc2'],\n",
    "                [\"maxpool\", \"pool2\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv3a\", [3, 3, 3, 128, 256], 'wc3a', 'bc3a'],\n",
    "                [\"conv\", \"conv3b\", [3, 3, 3, 256, 256], 'wc3b', 'bc3b'],\n",
    "                [\"maxpool\", \"pool3\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv4a\", [3, 3, 3, 256, 512], 'wc4a', 'bc4a'],\n",
    "                [\"conv\", \"conv4b\", [3, 3, 3, 512, 512], 'wc4b', 'bc4b'],\n",
    "                [\"maxpool\", \"pool4\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv5a\", [3, 3, 3, 512, 512], 'wc5a', 'bc5a'],\n",
    "                [\"conv\", \"conv5b\", [3, 3, 3, 512, 256], 'wc5b', 'bc5b'],\n",
    "                [\"maxpool\", \"pool5\", [1, 2, 2, 2, 1]],\n",
    "                [\"transpose\", [0, 1, 4, 2, 3]],\n",
    "                [\"reshape\", [-1, 8192]],\n",
    "                [\"fc\", \"fc1\", [8192, 4096], 'wd1', 'bd1', True],\n",
    "                [\"dropout\", \"dropout1\", self.keep_prob],\n",
    "                [\"fc\", \"fc2\", [4096, 4096],'wd2','bd2', True],\n",
    "                [\"dropout\", \"dropout2\", self.keep_prob],\n",
    "                [\"fc\", \"fc3\", [4096, self.num_class],'wout','bout',False],\n",
    "            ]\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                logits = self.parseNet(self.inputs, c3d_net)\n",
    "\n",
    "                int_label = self.labels\n",
    "\n",
    "                int_label=tf.cast(int_label,dtype=tf.int64)\n",
    "\n",
    "                result = tf.equal(tf.argmax(logits, axis=1), tf.argmax(int_label, axis=1))\n",
    "                softmax_logits = tf.nn.softmax(logits)\n",
    "\n",
    "                init = tf.global_variables_initializer()\n",
    "\n",
    "                sess.run(init)\n",
    "                saver = tf.train.Saver(tf.trainable_variables())\n",
    "                saver.restore(sess, tf.train.latest_checkpoint('../model/'))\n",
    "                print(\"Model Loading Done!\")\n",
    "\n",
    "                run_data = data\n",
    "                run_label = label\n",
    "\n",
    "                val_feed = {self.inputs: run_data, self.labels:run_label}\n",
    "\n",
    "                \n",
    "                return sess.run([result, softmax_logits], val_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../model/c3d.ckpt\n",
      "Model Loading Done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    c3dnet = Model()\n",
    "    plz = c3dnet.run(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([False, False,  True, False]),\n",
       " array([[0.22758774, 0.22611104, 0.11118398, 0.27755618, 0.15756111],\n",
       "        [0.19585584, 0.0920774 , 0.21830484, 0.13104963, 0.36271235],\n",
       "        [0.31943074, 0.14029083, 0.16314143, 0.23206736, 0.14506972],\n",
       "        [0.17570613, 0.21109188, 0.09827528, 0.14133485, 0.37359184]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
