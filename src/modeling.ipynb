{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import preprocessing as pre\n",
    "import tensorflow.contrib.layers as layers\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = pre.getDataFrame('S:raw/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-047ed65ff157>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12132101a90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.799999999999997"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = np.random.choice(len(data), 30, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 27, 12, 40, 14, 26, 30,  4, 43, 17, 42, 20,  1, 13, 34,  3, 10,\n",
       "       18, 21, 23, 25,  8, 31, 28,  5, 19, 33, 11, 15, 16])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = data[-test_index]\n",
    "# y_train = label[-test_index]\n",
    "X_train = data[train_index]\n",
    "y_train = label[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = data[:30]\n",
    "# y_train = label[:30]\n",
    "# X_test = data[30:]\n",
    "# y_test = label[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 72, 128, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self,\n",
    "            num_class = 5,\n",
    "            keep_prob = 0.6,\n",
    "            batch_size = 30,\n",
    "            epoch=1,\n",
    "            lr = 1e-4):\n",
    "        self.IMG_WIDTH = 128\n",
    "        self.IMG_HEIGHT = 72\n",
    "        \n",
    "        self.graph = tf.Graph()\n",
    "        self.num_class = num_class\n",
    "        self.epoch = epoch\n",
    "        self.CLIP_LENGTH = 30\n",
    "        self.keep_prob = keep_prob\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.n_step_epoch=int(30/batch_size)\n",
    "        with self.graph.as_default():\n",
    "            # [batch, in_depth, in_height, in_width, in_channels]\n",
    "            self.inputs = tf.placeholder(tf.float32, [None, self.CLIP_LENGTH, self.IMG_HEIGHT, self.IMG_WIDTH, 3])\n",
    "            self.labels = tf.placeholder(tf.int64, [None, 5])\n",
    "\n",
    "            self.initializer = layers.xavier_initializer()\n",
    "            self.global_step = tf.Variable(0, trainable = False, name = \"global_step\")\n",
    "            self.lr = lr\n",
    "            tf.add_to_collection(tf.GraphKeys.GLOBAL_STEP, self.global_step)\n",
    "         \n",
    "    def conv3d(self, inputs, shape, name, w_name, b_name):\n",
    "        with self.graph.as_default():\n",
    "            with tf.variable_scope('var_name') as var_scope:\n",
    "                W = tf.get_variable(name = w_name, shape = shape, initializer = self.initializer, dtype = tf.float32)\n",
    "                b = tf.get_variable(name = b_name, shape = shape[-1], initializer = tf.zeros_initializer(), dtype = tf.float32)\n",
    "                tf.add_to_collection(tf.GraphKeys.WEIGHTS, W)\n",
    "                tf.add_to_collection(tf.GraphKeys.BIASES, b)\n",
    "            return tf.nn.relu(tf.nn.bias_add(tf.nn.conv3d(inputs, W, strides = [1, 1, 1, 1, 1], padding = \"SAME\"), b))\n",
    "        \n",
    "    def fc(self, inputs, shape, name,w_name,b_name,activation = True):\n",
    "        with self.graph.as_default():\n",
    "            with tf.variable_scope('var_name') as var_scope:\n",
    "                W = tf.get_variable(name = w_name, shape = shape, initializer = self.initializer, dtype = tf.float32)\n",
    "                b = tf.get_variable(name = b_name, shape = shape[-1], initializer = tf.zeros_initializer(), dtype = tf.float32)\n",
    "                tf.add_to_collection(tf.GraphKeys.WEIGHTS, W)\n",
    "                tf.add_to_collection(tf.GraphKeys.BIASES, b)\n",
    "\n",
    "            if activation:\n",
    "                return tf.nn.relu(tf.nn.bias_add(tf.matmul(inputs, W), b))\n",
    "            else:\n",
    "                return tf.nn.bias_add(tf.matmul(inputs, W), b)\n",
    "            \n",
    "    def parseNet(self, net, netstruct, istraining = True):\n",
    "        for key in netstruct:\n",
    "            if key[0] == \"conv\":\n",
    "                net = self.conv3d(net, key[2], key[1],key[3], key[4])\n",
    "            elif key[0] == \"fc\":\n",
    "                net = self.fc(net, key[2], key[1], key[3], key[4],activation = key[-1])\n",
    "            elif key[0] == \"maxpool\":\n",
    "                net = tf.nn.max_pool3d(net, ksize = key[2], strides = key[2], padding = \"SAME\", name = key[1])\n",
    "            elif key[0] == \"dropout\" and istraining:\n",
    "                net = tf.nn.dropout(net, key[2], name = key[1])\n",
    "            elif key[0] == \"reshape\":\n",
    "                net = tf.reshape(net, key[-1])\n",
    "            elif key[0] == \"softmax\":\n",
    "                net = tf.nn.softmax(net)\n",
    "            elif key[0] == \"transpose\":\n",
    "                net = tf.transpose(net, perm=key[-1])\n",
    "        return net\n",
    "\n",
    "    def test(self, modelpath, data, label):\n",
    "        with self.graph.as_default():\n",
    "            \n",
    "#             [filter_depth, filter_height, filter_width, in_channels, out_channels]\n",
    "            c3d_net = [\n",
    "                [\"conv\", \"conv1\", [3, 3, 3, 3, 64], 'wc1', 'bc1'],\n",
    "                [\"maxpool\", \"pool1\", [1, 1, 2, 2, 1]],\n",
    "                [\"conv\", \"conv2\", [3, 3, 3, 64, 128], 'wc2', 'bc2'],\n",
    "                [\"maxpool\", \"pool2\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv3a\", [3, 3, 3, 128, 256], 'wc3a', 'bc3a'],\n",
    "                [\"conv\", \"conv3b\", [3, 3, 3, 256, 256], 'wc3b', 'bc3b'],\n",
    "                [\"maxpool\", \"pool3\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv4a\", [3, 3, 3, 256, 512], 'wc4a', 'bc4a'],\n",
    "                [\"conv\", \"conv4b\", [3, 3, 3, 512, 512], 'wc4b', 'bc4b'],\n",
    "                [\"maxpool\", \"pool4\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv5a\", [3, 3, 3, 512, 512], 'wc5a', 'bc5a'],\n",
    "                [\"conv\", \"conv5b\", [3, 3, 3, 512, 512], 'wc5b', 'bc5b'],\n",
    "                [\"maxpool\", \"pool5\", [1, 2, 2, 2, 1]],\n",
    "#                 [\"transpose\", [0, 1, 4, 2, 3]],  #only use it if you restore the sports1m_finetuning_ucf101.model, otherwise uncomment it,(e.g use conv3d_deepnetA_sport1m_iter_1900000_TF.model)\n",
    "                [\"reshape\", [-1, 8192]],\n",
    "                [\"fc\", \"fc1\", [8192, 4096], 'wd1', 'bd1', True],\n",
    "                [\"dropout\", \"dropout1\", self.keep_prob],\n",
    "                [\"fc\", \"fc2\", [4096, 4096],'wd2','bd2', True],\n",
    "                [\"dropout\", \"dropout2\", self.keep_prob],\n",
    "                [\"fc\", \"fc3\", [4096, self.num_class],'wout','bout',False],\n",
    "            ]\n",
    "\n",
    "            # print(tf.trainable_variables())\n",
    "            # print(var_list)\n",
    "            # print(tf.get_collection(tf.GraphKeys.WEIGHTS))\n",
    "\n",
    "            # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.5)\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                logits = self.parseNet(self.inputs, c3d_net)\n",
    "                softmax_logits = tf.nn.softmax(logits)\n",
    "                # int_label = tf.one_hot(self.labels, self.num_class)\n",
    "                int_label = self.labels  # [bs,101]-->[bs*4 or 8 or 16,101]\n",
    "                # int_label=tf.concat(\n",
    "                #     [int_label,int_label,int_label,int_label,],axis=0)\n",
    "\n",
    "                int_label=tf.cast(int_label,dtype=tf.int64)\n",
    "#                 task_loss = tf.reduce_sum(\n",
    "#                     tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=int_label))\n",
    "                task_loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = int_label))\n",
    "                # task_loss = -tf.reduce_sum(int_label*tf.log(logits))\n",
    "                acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(softmax_logits, axis=-1), int_label), tf.float32))\n",
    "                right_count = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(softmax_logits, axis=1), int_label), tf.int32))\n",
    "    \n",
    "                reg_loss = layers.apply_regularization(layers.l2_regularizer(5e-4),\n",
    "                                                       tf.get_collection(tf.GraphKeys.WEIGHTS))\n",
    "                total_loss = task_loss + reg_loss\n",
    "                # train_var_list = [v for v in tf.trainable_variables() if v.name.find(\"conv\") == -1]\n",
    "                train_op = tf.train.GradientDescentOptimizer(self.lr).minimize(\n",
    "                    total_loss, global_step=self.global_step)\n",
    "#                 train_op = tf.train.MomentumOptimizer(self.lr,0.9).minimize(\n",
    "#                     total_loss, global_step = self.global_step,var_list=train_var_list)\n",
    "    \n",
    "    \n",
    "                total_para = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])\n",
    "                print('total_para:', total_para)\n",
    "\n",
    "                init = tf.global_variables_initializer()\n",
    "                # var_list = [v for v in tf.trainable_variables() if v.name.find(\"conv\") != -1]  # 初始化只加载卷积层参数\n",
    "                # print(var_list)\n",
    "                # saver = tf.train.Saver(tf.global_variables())\n",
    "                sess.run(init)\n",
    "                saver = tf.train.Saver(tf.trainable_variables())\n",
    "                # saver.restore(sess, tf.train.latest_checkpoint(modelpath))\n",
    "                # saver.restore(sess, modelpath + \"sports1m_finetuning_ucf101.model\")\n",
    "                # print(\"Model Loading Done!\")\n",
    "                step = 0\n",
    "                print_freq = 2\n",
    "                \n",
    "                for one_epoch in range(self.epoch):\n",
    "                    epostarttime = time.time()\n",
    "                    starttime = time.time()\n",
    "                    total_v = 0.0\n",
    "                    test_correct_num = 0\n",
    "                    next_start_pos = 0\n",
    "                    for i in tqdm(range(int(len(data) / self.batch_size))):\n",
    "                        step += 1\n",
    "                        total_v += self.batch_size\n",
    "                        train_batch = data[next_start_pos:next_start_pos+self.batch_size] \n",
    "                        label_batch = label[next_start_pos:next_start_pos+self.batch_size] \n",
    "                        next_start_pos += self.batch_size \n",
    "                        assert len(train_batch)==self.batch_size\n",
    "                        val_feed = {self.inputs: train_batch, self.labels: label_batch}\n",
    "                        \n",
    "                        test_correct_num += sess.run(right_count, val_feed)\n",
    "                    print('test acc:', test_correct_num / total_v, 'test_correct_num:', test_correct_num,\n",
    "                          'total_v:', total_v)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_para: 78016261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                                                                                                              | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    c3dnet = Model()\n",
    "    c3dnet.test('path', X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
