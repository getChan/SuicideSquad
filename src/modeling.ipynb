{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import preprocessing as pre\n",
    "import tensorflow.contrib.layers as layers\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label = pre.getDataFrame('F:/raw/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_label = pre.getDataFrame('F:/raw/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55, 30, 112, 112, 3), (55, 5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35, 30, 112, 112, 3), (35, 5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24e07c33978>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[1][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self,\n",
    "            num_class = 5,\n",
    "            keep_prob = 0.6,\n",
    "            batch_size = 5,\n",
    "            epoch=1,\n",
    "            lr = 1e-4):\n",
    "        self.IMG_WIDTH = 112\n",
    "        self.IMG_HEIGHT = 112\n",
    "        \n",
    "        self.graph = tf.Graph()\n",
    "        self.num_class = num_class\n",
    "        self.epoch = epoch\n",
    "        self.CLIP_LENGTH = 30\n",
    "        self.keep_prob = keep_prob\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.n_step_epoch=int(30/batch_size)\n",
    "        with self.graph.as_default():\n",
    "            # [batch, in_depth, in_height, in_width, in_channels]\n",
    "            self.inputs = tf.placeholder(tf.float32, [None, self.CLIP_LENGTH, self.IMG_HEIGHT, self.IMG_WIDTH, 3])\n",
    "            self.labels = tf.placeholder(tf.int64, [None, self.num_class])\n",
    "\n",
    "            self.initializer = layers.xavier_initializer()\n",
    "            self.global_step = tf.Variable(0, trainable = False, name = \"global_step\")\n",
    "            self.lr = lr\n",
    "            tf.add_to_collection(tf.GraphKeys.GLOBAL_STEP, self.global_step)\n",
    "         \n",
    "    def conv3d(self, inputs, shape, name, w_name, b_name):\n",
    "        with self.graph.as_default():\n",
    "            with tf.variable_scope('var_name') as var_scope:\n",
    "                W = tf.get_variable(name = w_name, shape = shape, initializer = self.initializer, dtype = tf.float32)\n",
    "                b = tf.get_variable(name = b_name, shape = shape[-1], initializer = tf.zeros_initializer(), dtype = tf.float32)\n",
    "                tf.add_to_collection(tf.GraphKeys.WEIGHTS, W)\n",
    "                tf.add_to_collection(tf.GraphKeys.BIASES, b)\n",
    "            return tf.nn.relu(tf.nn.bias_add(tf.nn.conv3d(inputs, W, strides = [1, 1, 1, 1, 1], padding = \"SAME\"), b))\n",
    "        \n",
    "    def fc(self, inputs, shape, name,w_name,b_name,activation = True):\n",
    "        with self.graph.as_default():\n",
    "            with tf.variable_scope('var_name') as var_scope:\n",
    "                W = tf.get_variable(name = w_name, shape = shape, initializer = self.initializer, dtype = tf.float32)\n",
    "                b = tf.get_variable(name = b_name, shape = shape[-1], initializer = tf.zeros_initializer(), dtype = tf.float32)\n",
    "                tf.add_to_collection(tf.GraphKeys.WEIGHTS, W)\n",
    "                tf.add_to_collection(tf.GraphKeys.BIASES, b)\n",
    "\n",
    "            if activation:\n",
    "                return tf.nn.relu(tf.nn.bias_add(tf.matmul(inputs, W), b))\n",
    "            else:\n",
    "                return tf.nn.bias_add(tf.matmul(inputs, W), b)\n",
    "            \n",
    "    def parseNet(self, net, netstruct, istraining = True):\n",
    "        for key in netstruct:\n",
    "            if key[0] == \"conv\":\n",
    "                net = self.conv3d(net, key[2], key[1],key[3], key[4])\n",
    "            elif key[0] == \"fc\":\n",
    "                net = self.fc(net, key[2], key[1], key[3], key[4],activation = key[-1])\n",
    "            elif key[0] == \"maxpool\":\n",
    "                net = tf.nn.max_pool3d(net, ksize = key[2], strides = key[2], padding = \"SAME\", name = key[1])\n",
    "            elif key[0] == \"dropout\" and istraining:\n",
    "                net = tf.nn.dropout(net, key[2], name = key[1])\n",
    "            elif key[0] == \"reshape\":\n",
    "                net = tf.reshape(net, key[-1])\n",
    "            elif key[0] == \"softmax\":\n",
    "                net = tf.nn.softmax(net)\n",
    "            elif key[0] == \"transpose\":\n",
    "                net = tf.transpose(net, perm=key[-1])\n",
    "        return net\n",
    "\n",
    "    def train(self, data, label):\n",
    "        with self.graph.as_default():\n",
    "            \n",
    "#             [filter_depth, filter_height, filter_width, in_channels, out_channels]\n",
    "            c3d_net = [\n",
    "                [\"conv\", \"conv1\", [3, 3, 3, 3, 64], 'wc1', 'bc1'],\n",
    "                [\"maxpool\", \"pool1\", [1, 1, 2, 2, 1]],\n",
    "                [\"conv\", \"conv2\", [3, 3, 3, 64, 128], 'wc2', 'bc2'],\n",
    "                [\"maxpool\", \"pool2\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv3a\", [3, 3, 3, 128, 256], 'wc3a', 'bc3a'],\n",
    "                [\"conv\", \"conv3b\", [3, 3, 3, 256, 256], 'wc3b', 'bc3b'],\n",
    "                [\"maxpool\", \"pool3\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv4a\", [3, 3, 3, 256, 512], 'wc4a', 'bc4a'],\n",
    "                [\"conv\", \"conv4b\", [3, 3, 3, 512, 512], 'wc4b', 'bc4b'],\n",
    "                [\"maxpool\", \"pool4\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv5a\", [3, 3, 3, 512, 512], 'wc5a', 'bc5a'],\n",
    "                [\"conv\", \"conv5b\", [3, 3, 3, 512, 256], 'wc5b', 'bc5b'],\n",
    "                [\"maxpool\", \"pool5\", [1, 2, 2, 2, 1]],\n",
    "                [\"transpose\", [0, 1, 4, 2, 3]],  #only use it if you restore the sports1m_finetuning_ucf101.model, otherwise uncomment it,(e.g use conv3d_deepnetA_sport1m_iter_1900000_TF.model)\n",
    "                [\"reshape\", [-1, 8192]],\n",
    "                [\"fc\", \"fc1\", [8192, 4096], 'wd1', 'bd1', True],\n",
    "                [\"dropout\", \"dropout1\", self.keep_prob],\n",
    "                [\"fc\", \"fc2\", [4096, 4096],'wd2','bd2', True],\n",
    "                [\"dropout\", \"dropout2\", self.keep_prob],\n",
    "                [\"fc\", \"fc3\", [4096, self.num_class],'wout','bout',False],\n",
    "            ]\n",
    "\n",
    "            # print(tf.trainable_variables())\n",
    "            # print(var_list)\n",
    "            # print(tf.get_collection(tf.GraphKeys.WEIGHTS))\n",
    "\n",
    "            # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.5)\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                logits = self.parseNet(self.inputs, c3d_net)\n",
    "                softmax_logits = tf.nn.softmax(logits)\n",
    "                # int_label = tf.one_hot(self.labels, self.num_class)\n",
    "                int_label = self.labels  # [bs,101]-->[bs*4 or 8 or 16,101]\n",
    "                # int_label=tf.concat(\n",
    "                #     [int_label,int_label,int_label,int_label,],axis=0)\n",
    "\n",
    "                int_label=tf.cast(int_label,dtype=tf.int64)\n",
    "#                 task_loss = tf.reduce_sum(\n",
    "#                     tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=int_label))\n",
    "                task_loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = int_label))\n",
    "                # task_loss = -tf.reduce_sum(int_label*tf.log(logits))\n",
    "#                 acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(softmax_logits, axis=1), int_label), tf.float32))\n",
    "#                 right_count = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(softmax_logits, axis=1), int_label), tf.int32))\n",
    "    \n",
    "                reg_loss = layers.apply_regularization(layers.l2_regularizer(5e-4),\n",
    "                                                       tf.get_collection(tf.GraphKeys.WEIGHTS))\n",
    "                total_loss = task_loss + reg_loss\n",
    "                train_var_list = [v for v in tf.trainable_variables() if v.name.find(\"conv\") == -1]\n",
    "                train_op = tf.train.GradientDescentOptimizer(self.lr).minimize(\n",
    "                    total_loss, global_step=self.global_step)\n",
    "#                 train_op = tf.train.MomentumOptimizer(self.lr,0.9).minimize(\n",
    "#                     total_loss, global_step = self.global_step,var_list=train_var_list)\n",
    "#                 train_op = tf.train.AdamOptimizer(self.lr).minimize(total_loss)\n",
    "    \n",
    "    \n",
    "                total_para = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])\n",
    "                print('total_para:', total_para)\n",
    "\n",
    "                init = tf.global_variables_initializer()\n",
    "                # var_list = [v for v in tf.trainable_variables() if v.name.find(\"conv\") != -1]\n",
    "                # print(var_list)\n",
    "                # saver = tf.train.Saver(tf.global_variables())\n",
    "                sess.run(init)\n",
    "                saver = tf.train.Saver(tf.trainable_variables())\n",
    "                ############################################################\n",
    "                saver.restore(sess, tf.train.latest_checkpoint('../model/'))\n",
    "                ############################################################\n",
    "\n",
    "                # print(\"Model Loading Done!\")\n",
    "                step = 0\n",
    "                total_batch = int(len(data) / self.batch_size)\n",
    "                for epoch in range(self.epoch):\n",
    "                    next_start_pos = 0\n",
    "                    total_cost = 0\n",
    "                    for i in tqdm(range(total_batch)):\n",
    "                        train_batch = data[next_start_pos:next_start_pos+self.batch_size] \n",
    "                        label_batch = label[next_start_pos:next_start_pos+self.batch_size] \n",
    "                        next_start_pos += self.batch_size \n",
    "                        assert len(train_batch)==self.batch_size\n",
    "                        val_feed = {self.inputs: train_batch, self.labels: label_batch}\n",
    "#                         print(sess.run(tf.size(logits), val_feed))\n",
    "                        _, cost = sess.run([train_op, task_loss], val_feed)\n",
    "                        total_cost += cost\n",
    "                    print('Avg. cost:', total_cost / total_batch)\n",
    "                saver.save(sess, '../model/c3d.ckpt')\n",
    "                \n",
    "    def test(self, data, label):\n",
    "        with self.graph.as_default():\n",
    "            \n",
    "#             [filter_depth, filter_height, filter_width, in_channels, out_channels]\n",
    "            c3d_net = [\n",
    "                [\"conv\", \"conv1\", [3, 3, 3, 3, 64], 'wc1', 'bc1'],\n",
    "                [\"maxpool\", \"pool1\", [1, 1, 2, 2, 1]],\n",
    "                [\"conv\", \"conv2\", [3, 3, 3, 64, 128], 'wc2', 'bc2'],\n",
    "                [\"maxpool\", \"pool2\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv3a\", [3, 3, 3, 128, 256], 'wc3a', 'bc3a'],\n",
    "                [\"conv\", \"conv3b\", [3, 3, 3, 256, 256], 'wc3b', 'bc3b'],\n",
    "                [\"maxpool\", \"pool3\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv4a\", [3, 3, 3, 256, 512], 'wc4a', 'bc4a'],\n",
    "                [\"conv\", \"conv4b\", [3, 3, 3, 512, 512], 'wc4b', 'bc4b'],\n",
    "                [\"maxpool\", \"pool4\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv5a\", [3, 3, 3, 512, 512], 'wc5a', 'bc5a'],\n",
    "                [\"conv\", \"conv5b\", [3, 3, 3, 512, 256], 'wc5b', 'bc5b'],\n",
    "                [\"maxpool\", \"pool5\", [1, 2, 2, 2, 1]],\n",
    "                [\"transpose\", [0, 1, 4, 2, 3]],  #only use it if you restore the sports1m_finetuning_ucf101.model, otherwise uncomment it,(e.g use conv3d_deepnetA_sport1m_iter_1900000_TF.model)\n",
    "                [\"reshape\", [-1, 8192]],\n",
    "                [\"fc\", \"fc1\", [8192, 4096], 'wd1', 'bd1', True],\n",
    "                [\"dropout\", \"dropout1\", self.keep_prob],\n",
    "                [\"fc\", \"fc2\", [4096, 4096],'wd2','bd2', True],\n",
    "                [\"dropout\", \"dropout2\", self.keep_prob],\n",
    "                [\"fc\", \"fc3\", [4096, self.num_class],'wout','bout',False],\n",
    "            ]\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                logits = self.parseNet(self.inputs, c3d_net)\n",
    "                softmax_logits = tf.nn.softmax(logits)\n",
    "\n",
    "                int_label = self.labels\n",
    "\n",
    "                int_label=tf.cast(int_label,dtype=tf.int64)\n",
    "\n",
    "#                 right_count = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(softmax_logits, axis=1), int_label), tf.int32))    \n",
    "                acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, axis=1), tf.argmax(int_label, axis=1)), tf.float32))\n",
    "                total_para = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])\n",
    "                print('total_para:', total_para)\n",
    "\n",
    "                init = tf.global_variables_initializer()\n",
    "                \n",
    "                sess.run(init)\n",
    "                saver = tf.train.Saver(tf.trainable_variables())\n",
    "                saver.restore(sess, tf.train.latest_checkpoint('../model/'))\n",
    "                print(\"Model Loading Done!\")\n",
    "                \n",
    "#                 total_batch = int(len(data) / self.batch_size)\n",
    "                \n",
    "#                 next_start_pos = 0\n",
    "#                 cnt = 0\n",
    "                \n",
    "#                 for i in tqdm(range(total_batch)):\n",
    "#                     test_batch = data[next_start_pos:next_start_pos+self.batch_size] \n",
    "#                     label_batch = label[next_start_pos:next_start_pos+self.batch_size] \n",
    "#                     next_start_pos += self.batch_size \n",
    "#                     assert len(test_batch)==self.batch_size\n",
    "#                     val_feed = {self.inputs: test_batch, self.labels: label_batch}\n",
    "# #                         print(sess.run(tf.size(logits), val_feed))\n",
    "#                     cnt += sess.run(right_count, val_feed)\n",
    "                test_data = data\n",
    "                test_label = label\n",
    "            \n",
    "                val_feed = {self.inputs: test_data, self.labels:test_label}\n",
    "                \n",
    "                    \n",
    "                print('Accuracy:', sess.run(acc, val_feed))\n",
    "                \n",
    "    def run(self, data, label):\n",
    "        with self.graph.as_default():\n",
    "            c3d_net = [\n",
    "                [\"conv\", \"conv1\", [3, 3, 3, 3, 64], 'wc1', 'bc1'],\n",
    "                [\"maxpool\", \"pool1\", [1, 1, 2, 2, 1]],\n",
    "                [\"conv\", \"conv2\", [3, 3, 3, 64, 128], 'wc2', 'bc2'],\n",
    "                [\"maxpool\", \"pool2\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv3a\", [3, 3, 3, 128, 256], 'wc3a', 'bc3a'],\n",
    "                [\"conv\", \"conv3b\", [3, 3, 3, 256, 256], 'wc3b', 'bc3b'],\n",
    "                [\"maxpool\", \"pool3\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv4a\", [3, 3, 3, 256, 512], 'wc4a', 'bc4a'],\n",
    "                [\"conv\", \"conv4b\", [3, 3, 3, 512, 512], 'wc4b', 'bc4b'],\n",
    "                [\"maxpool\", \"pool4\", [1, 2, 2, 2, 1]],\n",
    "                [\"conv\", \"conv5a\", [3, 3, 3, 512, 512], 'wc5a', 'bc5a'],\n",
    "                [\"conv\", \"conv5b\", [3, 3, 3, 512, 256], 'wc5b', 'bc5b'],\n",
    "                [\"maxpool\", \"pool5\", [1, 2, 2, 2, 1]],\n",
    "                [\"transpose\", [0, 1, 4, 2, 3]],\n",
    "                [\"reshape\", [-1, 8192]],\n",
    "                [\"fc\", \"fc1\", [8192, 4096], 'wd1', 'bd1', True],\n",
    "                [\"dropout\", \"dropout1\", self.keep_prob],\n",
    "                [\"fc\", \"fc2\", [4096, 4096],'wd2','bd2', True],\n",
    "                [\"dropout\", \"dropout2\", self.keep_prob],\n",
    "                [\"fc\", \"fc3\", [4096, self.num_class],'wout','bout',False],\n",
    "            ]\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                logits = self.parseNet(self.inputs, c3d_net)\n",
    "\n",
    "                int_label = self.labels\n",
    "\n",
    "                int_label=tf.cast(int_label,dtype=tf.int64)\n",
    "\n",
    "                result = tf.equal(tf.argmax(logits, axis=1), tf.argmax(int_label, axis=1))\n",
    "\n",
    "                init = tf.global_variables_initializer()\n",
    "\n",
    "                sess.run(init)\n",
    "                saver = tf.train.Saver(tf.trainable_variables())\n",
    "                saver.restore(sess, tf.train.latest_checkpoint('../model/'))\n",
    "                print(\"Model Loading Done!\")\n",
    "\n",
    "                run_data = data\n",
    "                run_label = label\n",
    "\n",
    "                val_feed = {self.inputs: run_data, self.labels:run_label}\n",
    "\n",
    "\n",
    "                return sess.run(result, val_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_para: 74477061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [09:35<00:00, 52.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. cost: 14.538407010110943\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    c3dnet = Model()\n",
    "    c3dnet.train(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_para: 74477061\n",
      "INFO:tensorflow:Restoring parameters from ../model/c3d.ckpt\n",
      "Model Loading Done!\n",
      "Accuracy: 0.17142858\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    c3dnet = Model()\n",
    "    c3dnet.test(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
